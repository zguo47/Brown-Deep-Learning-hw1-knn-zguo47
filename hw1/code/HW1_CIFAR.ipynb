{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819fce40-39b3-4bfd-8599-69f96e555012",
   "metadata": {},
   "source": [
    "# CS1470/2470 HW1: KNN (with CIFAR)\n",
    "\n",
    "In this homework assignment, you will experience the overall machine learning process from start to end by implementing your own version of the **k-Nearest Neighbors** algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d699f6d-5008-46aa-8f56-f887e00c404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -VV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998b6d7-8d03-46f6-83a3-0c2e2671faf1",
   "metadata": {},
   "source": [
    "If you are running the notebook on Colab, you need to mount your drive or repo. An example of these is provided [here](https://colab.research.google.com/drive/1ioIGn7zOp46lgMEcL4P54Y9Y_z7PnI7K?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2dd7b8-04b2-41e9-a246-71c4e716cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "## Path to data\n",
    "data_path = \"../data\"\n",
    "kitten_path = \"kitten.jpg\"\n",
    "\n",
    "## Make sure the data is downloaded appropriately\n",
    "![ ! -d \"$data_path\" ] && cd .. && bash download.sh && cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88a600-491a-4b97-88d0-76a23a00d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport KNN_Model, preprocess\n",
    "from ResNetWrapper import ResNetWrapper\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ensures that we run only on cpu\n",
    "# this environment variable is not permanent\n",
    "# it is valid only for this session\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204c7d4-04b6-403a-95f8-3d1ac03f4941",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b1a32-5989-453e-bae0-ec1b08282ca0",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04fe06-161e-4cd3-9dfc-257ec82efd6a",
   "metadata": {},
   "source": [
    "In a machine learning project, you need a separate train set and a test set. Sometimes, you also need a validation set to fit hyperparameters, but for this homework assignment, we are not going to use a validation set. \n",
    "\n",
    "<span style=\"color:blue;font-weight:bold\">Code Block #1: Preprocessing</span>\n",
    "\n",
    "1. Unpickle the CIFAR files and load the full train and test datasets by using the function `get_data_CIFAR` in `preprocess.py`.\n",
    "2. Shuffle the full datasets with your favorite random seed by using the function `shuffle_data` in `preprocess.py`. Please use the same random seed for both train and test sets.\n",
    "3. Keep only a small subset of the full datasets by using the function `get_subset` in `preprocess.py`.\n",
    "   - For the train set, keep only 100 images and labels for each class, so that your train image array should have the shape (1000, 32, 32, 3), and your train label array should have the shape (1000,)\n",
    "   - For the test set, 25 images and labels for each class, so the shapes are (250, 32, 32, 3), and (250,).\n",
    "   - The variable names of the test and train image arrays must be `image_train_uint` and `image_test_uint`.\n",
    "4. Normalize the image arrays by dividing them with 255.0, convert the data type to np.float32, and flatten the images. \n",
    "   - However, DO NOT throw away the np.uint8 images from TODO #3, because we need them for the ResNet.\n",
    "   - The final train image array should have the shape (1000, 3072), and the final test image array (250, 3072)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4c58a-02fe-4449-9f91-1b557657bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport preprocess\n",
    "from preprocess import *\n",
    "\n",
    "# TODO #1: \n",
    "#   Unpickle the CIFAR files and load the full train and test datasets  \n",
    "#   by using the function unpickle_CIFAR in preprocess.py.\n",
    "image_train_full, label_train_full, cifar_class_list = None, None, None\n",
    "image_test_full,  label_test_full,  _  = None, None, None\n",
    "\n",
    "# TODO #2: \n",
    "#   Shuffle the full datasets with your favorite random seed\n",
    "#   by using the function shuffle_data in preprocess.py.\n",
    "#   Please use the same random seed for both train and test sets.\n",
    "seed = 12\n",
    "image_train_full, label_train_full = None, None\n",
    "image_test_full,  label_test_full  = None, None\n",
    "\n",
    "# TODO #3: \n",
    "#   Keep only a small subset of the full datasets by using the function\n",
    "#     get_subset in preprocess.py.\n",
    "#   For the train set, keep only 100 images and labels for each class, \n",
    "#     so that your train image array should have the shape (1000, 32, 32, 3), \n",
    "#     and your train label array should have the shape (1000,)\n",
    "#   For the test set, 25 images and labels for each class,\n",
    "#     so the shapes are (250, 32, 32, 3), and (250,)\n",
    "#   The variable names of the test and train image arrays must be \n",
    "#     \"image_train_uint\" and \"image_test_uint\"\n",
    "image_train_uint, label_train = None, None\n",
    "image_test_uint,  label_test  = None, None\n",
    "\n",
    "# TODO #4: \n",
    "#   Normalize the image arrays by dividing them with 255.0,\n",
    "#     convert the data type to np.float32,\n",
    "#     and flatten the images. \n",
    "#   However, DO NOT throw away the np.uint8 images from TODO #3,\n",
    "#     because we need them for the ResNet.\n",
    "#   The final train image array should have the shape (1000, 3072),\n",
    "#     and the final test image array (250, 3072).\n",
    "image_train = None\n",
    "image_test  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48d12c-f380-4744-bea4-07891d3ea0f8",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee815793-0b7f-4e8f-a1d5-edb8f039887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_inspect = range(0, 1000, 100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 10)\n",
    "fig.set_size_inches(12, 1.2)\n",
    "\n",
    "for i, each_image in enumerate(indices_to_inspect):\n",
    "    ax[i].imshow(image_train[each_image].reshape(32, 32, 3))\n",
    "    ax[i].tick_params(left=False)\n",
    "    ax[i].tick_params(bottom=False)\n",
    "    ax[i].tick_params(labelleft=False)\n",
    "    ax[i].tick_params(labelbottom=False)\n",
    "    ax[i].set_xlabel(f\"{each_image}\")\n",
    "    ax[i].set_title(f\"{label_train[each_image]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03259c7-a8fd-4f56-a4c5-093bdb86a5fa",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c6936-8455-4492-a3af-5b44a1e0f63a",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c490937-d310-457c-bb31-7961f17085a0",
   "metadata": {},
   "source": [
    "Now it's time to make your own implementation of the k-Nearest Neighbors algorithm.\n",
    "\n",
    "<span style=\"color:blue;font-weight:bold\">Code Block #2: Building the model</span>\n",
    "\n",
    "Create a KNN model, or an instance of the class KNN_Model and fit it with the train dataset. \n",
    "- Although, `k_neighbors` can be any integer in theory, keep `k_neighbors == 9` in this homework assignment. \n",
    "- The name of the KNN_Model instance must be `model_cifar`, so that you can run the following Code Blocks without trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9e6db-5b32-4762-9220-88b1cb730848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KNN_Model import KNN_Model\n",
    "\n",
    "## TODO\n",
    "model_cifar = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30f915-0740-4e4a-85e9-4cf7f9e6ec99",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10473f07-29ea-4a3a-a194-2477296c5b37",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #3: Interacting with the model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull in a specific image\n",
    "sample_image = image_test[88].copy()\n",
    "## TODO: Show what the image looks like using plt.imshow\n",
    "## Make sure to title it using plt.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1405f6-4e12-42f3-9f30-91de031e62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Show what the image looks like using plt.imshow\n",
    "## Make sure to title it using plt.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cbcbf-7512-43b8-8780-dacd9136d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Figure out the closest k neighbors based on the model.\n",
    "class_counts, nearest_indices = None, None\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce80ee5-4379-46b2-9730-525acbcd06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_knn, ax_knn = plt.subplots()\n",
    "\n",
    "ax_knn.barh(y=cifar_class_list, width=class_counts, zorder=100)\n",
    "ax_knn.invert_yaxis()\n",
    "ax_knn.set_xticks(np.arange(1 + np.max(class_counts)))\n",
    "ax_knn.set_yticks(cifar_class_list)\n",
    "ax_knn.set_title(\"KNN Classification on a Test Image\", fontsize=14)\n",
    "ax_knn.set_xlabel(\"True Labels of Nearest Neighbors\", fontsize=14)\n",
    "ax_knn.grid(linestyle=\"dashed\", color=\"#bfbfbf\", zorder=-100)\n",
    "fig_knn.set_size_inches([6, 4])\n",
    "\n",
    "## You can also save the figure in the pdf, png, and svg formats\n",
    "# fig.savefig(f\"KNN_Test_Image_CIFAR.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f636f-b849-4899-80a2-f06314369df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_nearest, ax_nearest = plt.subplots(3, 3, figsize=(4.5, 4.5))\n",
    "\n",
    "for each_ax, each_neighbor in zip(ax_nearest.flat, nearest_indices):\n",
    "    each_ax.imshow(model_cifar.image_train[each_neighbor].reshape(32, 32, 3), cmap=\"Greys\")\n",
    "    each_ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    each_ax.text(2, 5, model_cifar.label_train[each_neighbor], \n",
    "        fontsize=8, bbox = dict(color=\"White\", alpha=0.75))\n",
    "    fig_nearest.suptitle(\"Nearest Images\", y = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1a4ae-3bd1-45b0-97b5-04b9bf363e41",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909b242-0404-4b67-a15b-39c970bd3f2d",
   "metadata": {},
   "source": [
    "It is time to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7f1d7-15a7-47b2-be62-48ad8bab6c5a",
   "metadata": {},
   "source": [
    "### Overall Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b375e-84ac-482d-80d8-135e3928029d",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #4: Overall accuracy</span>\n",
    "\n",
    "1. Get predictions on every image in the test dataset. \n",
    "2. Calculate and print out the overall accuracy of the model, which is defined as the number of correct predictions divided by the number of all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f99b9-1ccd-4427-ba05-4e4055f868c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## TODO: Get the accuracy on the test dataset\n",
    "prediction_array = None\n",
    "prediction_acc = None\n",
    "print(f\"accuracy = {prediction_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610562a6-3b21-4095-b2f2-5a3def397d45",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ecfec-2c7d-4156-891d-9a9d2aac15cd",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #5: Confusion matrix</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df8094-8f68-4db1-b7ae-9ad06a3391f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the confusion matrix (hint: see KNN_ConfMtx)\n",
    "confusion_mat = None\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d094a-8bdb-458a-b21c-3c96ad1c86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_confusion1, ax_confusion1 = model_cifar.visualize_confusion_matrix(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b3c30-a80a-4db8-9d07-f82d64e02a5e",
   "metadata": {},
   "source": [
    "## Pretrained ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a82a79-749e-48ca-98bf-ed50e7e1ee8f",
   "metadata": {},
   "source": [
    "### KNN on ResNet Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b1da32-5046-4ba8-a733-e4b63bc643c4",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #6: More preprocessing for ResNet50</span>\n",
    "\n",
    "From now on, use `image_train_embeddings` instead of `image_train`, and use `image_test_embeddings` instead of `image_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a53107-eef5-4aeb-9478-4448225cacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rs_wrapper = ResNetWrapper()\n",
    "\n",
    "image_train_resnet = rs_wrapper.preprocess_image(image_train_uint)\n",
    "image_test_resnet  = rs_wrapper.preprocess_image(image_test_uint)\n",
    "\n",
    "image_train_embeddings = rs_wrapper.get_resnet_embeddings(image_train_resnet)\n",
    "image_test_embeddings  = rs_wrapper.get_resnet_embeddings(image_test_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf21932-9fad-42c8-9377-897e85ff6389",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #7: Building the model again, because ResNet</span>\n",
    "\n",
    "Create a KNN model, or an instance of the class KNN_Model and fit it with the train dataset. \n",
    "- Although, `k_neighbors` can be any integer in theory, keep `k_neighbors == 9` in this homework assignment. \n",
    "- The name of the KNN_Model instance must be `model_resnet`, so that you can run the following Code Blocks without trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e5d6f-4d45-4531-938b-c5f6f1515e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Train the KNN Model on the ResNet embeddings of the trained data\n",
    "model_resnet = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601a50f-b3b0-4ea3-bc62-125c65f2cb24",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #8: Overall accuracy of KNN + ResNet</span>\n",
    "\n",
    "1. Get predictions on every image embeddings in the test dataset. \n",
    "2. Calculate and print out the overall accuracy of the model, which is defined as the number of correct predictions divided by the number of all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4ad5b-0d4e-4bc1-a278-6e5f8ced1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## TODO: Get testing accuracy on model working with ResNet embeddings\n",
    "prediction_array2 = None\n",
    "prediction_acc2 = None\n",
    "print(f\"accuracy = {prediction_acc2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f3d0e-6561-4fe3-be90-5ba45d8def9b",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #9: Confusion matrix of KNN + ResNet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82de449-b8f5-49e6-a960-28855a865394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Compute the confusion matrix for this new model as before\n",
    "confusion_mat2 = None\n",
    "print(confusion_mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350183ca-07db-460a-a03e-687166d268e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_confusion2, ax_confusion2 = model_resnet.visualize_confusion_matrix(confusion_mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f629ea1-1486-4e95-b8e9-cf2051cdf2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts, nearest_indices = model_resnet.get_neighbor_counts(image_test_embeddings[88], return_indices=True)\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a5e51-581d-4177-a07e-c0ced1978cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_resnet, ax_resnet = plt.subplots()\n",
    "\n",
    "class_counts, nearest_indices = model_resnet.get_neighbor_counts(image_test_embeddings[88], return_indices=True)\n",
    "ax_resnet.barh(y=cifar_class_list, width=class_counts, zorder=100)\n",
    "ax_resnet.invert_yaxis()\n",
    "ax_resnet.set_xticks(np.arange(1 + np.max(class_counts)))\n",
    "ax_resnet.set_yticks(cifar_class_list)\n",
    "ax_resnet.set_title(\"KNN-Resnet Hybrid Classification on a Test Image\", fontsize = 14)\n",
    "ax_resnet.set_xlabel(\"True Labels of Nearest Neighbors\", fontsize = 14)\n",
    "ax_resnet.grid(linestyle=\"dashed\", color=\"#bfbfbf\", zorder= -100)\n",
    "fig_resnet.set_size_inches([6, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ba523-fc3c-4dd2-a3dd-5872bb984874",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_nearest2, ax_nearest2 = plt.subplots(3, 3, figsize=(4.5, 4.5))\n",
    "\n",
    "for each_ax, each_neighbor in zip(ax_nearest2.flat, nearest_indices):\n",
    "    each_ax.imshow(image_train_uint[each_neighbor], cmap=\"Greys\")\n",
    "    each_ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    each_ax.text(2, 5, label_train[each_neighbor], \n",
    "        fontsize=8, bbox = dict(color=\"White\", alpha=0.75))\n",
    "    fig_nearest2.suptitle(\"Nearest Images\", y = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af253f54-a946-423a-a77e-ea6c8055d208",
   "metadata": {},
   "source": [
    "### Full ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09053f-1d38-4276-abb5-39be97574287",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_compare, ax_compare = plt.subplots(1, 2)\n",
    "ax_compare[0].imshow(image_test_uint[88])\n",
    "ax_compare[1].imshow(plt.imread(kitten_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785399b-b1ce-472c-ab60-3181c35afdc9",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight:bold\">Code Block #10: Full power of the ResNet50 model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61b47d-25fc-4a98-9a31-fce55dd9d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rs_wrapper.get_full_model_predictions(image_test_resnet[88]))\n",
    "\n",
    "kitten_image_full = plt.imread(kitten_path)\n",
    "kitten_image_full = np.array(kitten_image_full)\n",
    "\n",
    "## TODO: Get the ResNet model predictions on the kitten image above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
